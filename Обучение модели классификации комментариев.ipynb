{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pymystem3 import Mystem as m\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем датасет и сохраним его в переменную 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('C:/Users/FunnyFunFruit/Desktop/ЯндексПрактикум/Проекты/Машинное обучение для текстов/toxic_comments.csv',\n",
    "                  index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим строки и размер датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83924</th>\n",
       "      <td>\":Thanks for the second award. Now where is Ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75667</th>\n",
       "      <td>====\\n\\nVendetta87the name says it allis obvio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123048</th>\n",
       "      <td>Richard is a gay dancing HOBO&gt;HOBO&gt;HOBO!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132500</th>\n",
       "      <td>I came over here to suggest the same thing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55223</th>\n",
       "      <td>Warning \\n\\nWikipedia is not a gameguide. Too ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "83924   \":Thanks for the second award. Now where is Ba...      0\n",
       "75667   ====\\n\\nVendetta87the name says it allis obvio...      0\n",
       "123048           Richard is a gay dancing HOBO>HOBO>HOBO!      1\n",
       "132500        I came over here to suggest the same thing.      0\n",
       "55223   Warning \\n\\nWikipedia is not a gameguide. Too ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функции для леммтаизации и очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    import nltk\n",
    "    from nltk import pos_tag\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import wordnet\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    def get_wordnet_pos(word):\n",
    "        import nltk\n",
    "        from nltk import pos_tag\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        from nltk.corpus import wordnet\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    import nltk\n",
    "    from nltk import pos_tag\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "def clear_text(text):\n",
    "    import re\n",
    "    return ' '.join(re.sub(r\"[^a-zA-Z]\", ' ', text).lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функции к датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368c9531d0654b0d95945c6a211026c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=19912), Label(value='0 / 19912')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 484 ms\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].parallel_apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1919ff1a0ef49278340f2c9446d2825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=19912), Label(value='0 / 19912')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.9 s\n",
      "Wall time: 9min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].parallel_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101174    thanks arabic be a language option but not a c...\n",
       "4394      something anonymous edit have give rise to van...\n",
       "146709    do you have a reliable source for these detail...\n",
       "118029    support all the source call it an islamic cent...\n",
       "41484                    great article wikipedia jimbo wale\n",
       "29186     i also ask whether you be give an assessment o...\n",
       "151483    the only other option to evisceration might be...\n",
       "80775     no it isn t pathetic i have well thing to do t...\n",
       "55165     cfd thanks i thought the tool would do this au...\n",
       "2417      thanks alan thanks for the intro to wiki you d...\n",
       "73648     for what i never personally attack anyone he b...\n",
       "113281    note one buzzfeed article have suggest that th...\n",
       "85556     barrett on corporal clegg some source i ve rea...\n",
       "115435    why their not heavy metal can t you just accep...\n",
       "81398                need reference no source unref tag add\n",
       "79021     i think you have not see that i do reply to yo...\n",
       "148979    theresa i would urge caution to the torch and ...\n",
       "88403     ref tag remove i ve remove the reference need ...\n",
       "19831     tyranny of average i ve create an article that...\n",
       "100106                         mar utc use most common name\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85852\n",
      "1     9723\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.4)\n",
    "\n",
    "print(data_train['toxic'].value_counts())\n",
    "\n",
    "r = len(data_train.loc[data_train['toxic']==0])//len(data_train.loc[data['toxic']==1])\n",
    "\n",
    "\n",
    "df_1 = data_train.loc[data_train['toxic']==1]\n",
    "df_1 = data_train.loc[df_1.index.repeat(r)]\n",
    "data_train = pd.concat([data_train.loc[data_train['toxic']==0], df_1]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85852\n",
       "1    77784\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на обучающую, валидационную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = data_train['text']\n",
    "target_train = data_train['toxic']\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(data_test['text'], data_test['toxic'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем текст через TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = count_tf_idf.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_valid = count_tf_idf.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression(C=5, max_iter=100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и предскажем токсичность комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика модели линейной регрессии: 0.780\n",
      "CPU times: total: 52.3 s\n",
      "Wall time: 6.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_1.fit(tf_idf, target_train)\n",
    "\n",
    "pred_1 = model_1.predict(tf_idf_valid)\n",
    "\n",
    "print('F1 метрика модели линейной регрессии: {:.3f}'.format(f1_score(target_valid, pred_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 метрика показала 0.780, что является приемлимым результатом для данной работы по ТЗ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также предстказать токсичность комментариев через классификатор случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика классификационной модели случайного леса: 0.454\n",
      "CPU times: total: 13.9 s\n",
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_2 = RandomForestClassifier()\n",
    "\n",
    "params = {'n_estimators' : range(1, 500, 100),\n",
    "          'max_depth' : range(1, 20, 5),\n",
    "          'min_samples_leaf' : range(2, 20, 4),\n",
    "          'min_samples_split' : range(2, 20, 4)}\n",
    "\n",
    "search = RandomizedSearchCV(model_2, param_distributions=params, scoring='f1', n_jobs=-1)\n",
    "search.fit(tf_idf, target_train)\n",
    "\n",
    "model_2 = search.best_estimator_\n",
    "\n",
    "pred_2 = model_2.predict(tf_idf_valid)\n",
    "\n",
    "f1_2 = f1_score(target_valid, pred_2)\n",
    "\n",
    "print('F1 метрика классификационной модели случайного леса: {:.3f}'.format(f1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель классификации случайного леса показала F1 метрику 0.454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем классифицировать текст через предобученную модель-трансофрмер Martin-ha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем токенайзер и саму модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('martin-ha/toxic-comment-model')\n",
    "model_3 = transformers.AutoModelForSequenceClassification.from_pretrained('martin-ha/toxic-comment-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пайплайн из набора пайплайнов библиотеки Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_3 = transformers.TextClassificationPipeline(model=model_3, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем токсичность комментариев и посмотрим F1 метрику на 10000 семплов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экономии времени возьмем выборку из 10000 сэмплов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bert = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d42453469245c3993f510fd31d54f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели BERT: 0.677\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "\n",
    "for text in notebook.tqdm(data_bert['text']):\n",
    "    pred = pipeline_3(text[:512])\n",
    "    y_pred.append(1 if pred[0]['label'] == 'toxic' else 0)\n",
    "    \n",
    "f1_bert = f1_score(data_bert['toxic'], y_pred)\n",
    "print('Метрика F1 модели BERT: {:.3f}'.format(f1_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель BERT показала метрику 0.677 на 10000 семплов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам валидации лучшей моделью оказалась модель логистической регрессии. Поэтому проверим ее на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678181023174464"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model_1.predict(tf_idf_test)\n",
    "f1_score(target_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из проделанного выше исследования следует вывод, что хуже всех с заданием справилась модель классификации случайного леса (0.454). Далее идет модель BERT (F1=0.677), наилучший результат показала модель линейной регрессии (0.767). Также стоит отметить скорость линейной регрессии, модель обучается и предсказывает ответы в течение минуты. В противовес этому стоит сказать, что модель BERT удобна в написании кода, она вся взята из библиотек, предобработка данных идет через стандартный токенизатор, а дальнейшая работа через стандартный пайплайн.<br>\n",
    "Таким образом выбирать модель следует из того, что нужно конечному потребителю: удобство написания кода или скорость обработки и точность модели. В любом случае BERT, случайный лес и линейная регрессия в данном контексте являются приемлимыми <br>\n",
    "Стоит также отметить, что до обработки дисбаланса классов случайный лес и модель BERT менялись местами. После обработки дисбаланса у всех моделей поднялась метрика F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
